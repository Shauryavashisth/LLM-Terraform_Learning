{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\shaur\\\\Desktop\\\\icici policies wording'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, nltk, re\n",
    "from langchain.document_loaders import PyPDFLoader, WebBaseLoader\n",
    "from langchain.text_splitter import NLTKTextSplitter,RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from pathlib import Path as p\n",
    "os.environ[\"OPENAI_API_KEY\"]=open(r\"C:\\Users\\shaur\\Downloads\\chat_gpt_key.txt\",'r').read()\n",
    "os.chdir(r\"C:\\Users\\shaur\\Desktop\\icici policies wording\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pages from Comparison.pdf:- 3\n",
      "Length of pages from Elevate Policy Wordings.pdf:- 45\n",
      "Length of pages from Health AdvantEdge_Policy wordings_IL.pdf:- 51\n",
      "Length of pages from policy-wordings_maxprotect.pdf:- 40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['Comparison.pdf', 'Elevate Policy Wordings.pdf', 'Health AdvantEdge_Policy wordings_IL.pdf', 'policy-wordings_maxprotect.pdf'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_policies_pdfs = [i for i in os.listdir() if '.pdf' in i]\n",
    "all_policies_dict = {}\n",
    "for i in range(0,len(all_policies_pdfs)):\n",
    "    loader = PyPDFLoader(all_policies_pdfs[i])\n",
    "    pages = loader.load()\n",
    "    pages = [page.page_content for page in pages]\n",
    "    print(f\"Length of pages from {all_policies_pdfs[i]}:- {len(pages)}\")\n",
    "    all_policies_dict[all_policies_pdfs[i]] = pages\n",
    "all_policies_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### (FAILED) getting summary from Policybazar for the comparision of these 3 policy\n",
    "# loader = WebBaseLoader(\"https://pbhealth.policybazaar.com/quote-compare-2?encenq=emRrNkN3aEk4TlBwdzZwLzc4NXRZMGRlRzFkbE5pL2JYQmlOaFBLUm5iUT0&enquiryid=NzU3NzI1ODk0&k=eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJFbnF1aXJ5SWQiOjc1NzcyNTg5NCwiRXhwaXJ5VGltZSI6MTc0NTc0MjM2OSwiUm9sZSI6bnVsbH0.GkSkfmCCjxhe3pYejDkhMyVvKZj2LxVR3JDBOujUE1RzG3W-oWkxJ32Nyb9e33WEvEVqflbUduzokJ5Nju8XepIY0kjivduTKeyfZhljIMkWjCZ9IxJnYw9_dQg23z0BAldA36UL9Tw-e6VgM46Do7ehY7byPWdYfRcE1zCkQyc&plan=80950-1000000-Elevate-3-ICICI%20Lombard-8739-0-2-1&plan=80843-10000000-Max%20Protect%20Classic-3-ICICI%20Lombard-16724-0-2-1&plan=80045-1000000-Health%20AdvantEdge-3-ICICI%20Lombard-12282-0-2-1&profileid=147272833&utm_source=MYACC_M\")\n",
    "# documents = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_policies_dict['Elevate Policy Wordings.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_policies_dict['Health AdvantEdge_Policy wordings_IL.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_policies_dict['policy-wordings_maxprotect.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Removing footer details from the PDF's\n",
    "\n",
    "repeted_text_0 = 'IRDA Reg. No. 115\\nMailing Address:\\n601 / 602, 6th Floor, Interface Building No. 16,\\nNew Link Road, Malad (West), \\nMumbai - 400 064.CIN:  L67200MH2000PLC129408\\nRegistered Office Address:\\nICICI Lombard House, 414, P Balu Marg, Off \\nVeer Savarkar Road, Nr Siddhi Vinayak Temple, \\nPrabhadevi, Mumbai - 400 025.UIN: ICIHLIP25048V042425 Product Name: Elevate\\nToll free No.  : 1800 2666  \\nAlternate No.: 86552 22666 (Chargeable)\\nWebsite :  www.iciclombard.com\\nE-mail : customersupport@icicilombard.comICICI Lombard General Insurance Company Limited'\n",
    "repeted_text_1 = 'Health AdvantEdge  \\nICICI Lombard General Insurance Company Limited  \\n       IRDA  Reg. No. 115                            CIN : L67200MH2000PLC129408                                  UIN: ICIHLIP24182V042324     Health A dvantEdge  \\n       Mailing A ddress:                              Registered Office A ddress:                                Toll free no : 1800 2666   \\n601 & 602, 6th Floor, Interf ace 16,    ICICI Lombard House, 414, P Balu Marg,                     A lternate no :  86552 2 2666 (chargeable)   \\nNew Linking Road, Malad (West)      Of f  Veer Sav arkar Road, Nr Siddhi Vinay ak Temple,    E-mail : customersupport@icicilombard.com  \\n    Mumbai - 400 064                             Prabhadev i, Mumbai 400 025                                        Website : www.icicilombard.com   '\n",
    "repeted_text_2 = 'Annexure I  MaxProtect  Policy w ordings  \\nIRDAI reg. no.: 115                CIN: L67200MH20000PLC129408   UIN: ICIHLIP24084V012324'\n",
    "for i in all_policies_dict.keys():\n",
    "    for k in [repeted_text_0,repeted_text_1,repeted_text_2]:\n",
    "        all_policies_dict[i] = [page.replace(k.strip(), '').strip() for page in all_policies_dict[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Symentic based chunking\n",
    "### Using RecursiveCharacterTextSplitter (found that the context was missing or changed and the sentenses were getting cut from between)\n",
    "### Using NLTKTextSplitter (found that the context was being saved and the sentenses were complete)\n",
    "# splitter = NLTKTextSplitter(chunk_size=1200, chunk_overlap=300)\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2500,\n",
    "    chunk_overlap=1000,\n",
    "    separators=[\"\\n\\n\", \"\\n\", r\"\\. \\s\"]\n",
    ")\n",
    "chunked_policies = {}\n",
    "for i, full_text in all_policies_dict.items():\n",
    "    full_text = \"\\n\".join(full_text)\n",
    "    docs = splitter.create_documents([full_text])\n",
    "    chunked_policies[i] = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a. PREAMBLE:\n",
      "  ICICI Lombard General Insurance Company Limited \n",
      "(“We/Us”), having received a Proposal and the premium \n",
      "from the Proposer named in Part A of the Policy \n",
      "(hereinafter referred to as the “Policy Schedule”) and the \n",
      "said Proposal form with any statement, report or other \n",
      "document leading to the issue of this Policy and referred \n",
      "to therein having been accepted and agreed to by Us \n",
      "and the Proposer as the basis of this contract do, by this \n",
      "Policy agree, in consideration of and subject to the due \n",
      "receipt of the subsequent premiums, as set out in the \n",
      "Policy Schedule. \n",
      "  Further, subject to the Policy terms and conditions that \n",
      "on proof to Our satisfaction of the compensation having \n",
      "become payable as set out in the Policy Schedule to the \n",
      "said person or persons claiming payment or occurencean \n",
      "event upon which one or more benefits become payable \n",
      "under this Policy, the Annual Sum Insured / appropriate \n",
      "benefit amount will be paid by Us.\n",
      "b. DEFINITIONS:\n",
      "  For the purposes of this Policy, the terms specified below \n",
      "shall have the meaning set forth wherever appearing/\n",
      "specified in this Policy or related Add-ons/Optional \n",
      "Covers:\n",
      "  Where the context so requires, references to the singular \n",
      "shall also include references to the plural and references \n",
      "to any gender shall include references to all genders. \n",
      "Further any references to statutory enactment include \n",
      "subsequent changes to the same.\n",
      "i.\t Standard\tDefinitions\t\n",
      "  “Accident”  means a sudden, unforeseen and involuntary \n",
      "event caused by external, visible and violent means. \n",
      " \t“Any\tone\tIllness”  means continuous period of Illness \n",
      "and it includes a relapse within 45 days from the date of \n",
      "last consultation with the Hospital/Nursing Home where \n",
      "treatment may have been taken. \n",
      "  “Ayush\tTreatment”  refers to the medical and / or \n",
      "hospitalization treatments given under ‘Ayurveda, Yoga \n",
      "and Naturopathy, Unani, Siddha and Homeopathy \n",
      "systems. \n",
      " \t“Break\tin\tpolicy”  means the period of gap that occurs at \n",
      "the end of the existing policy term / installment premium \n",
      "due date, when the premium due for renewal on a given \n",
      "policy or installment premium due is not paid on or before \n",
      "the premium renewal date or grace period. \n",
      "  “Cashless\t facility”  means a facility extended by the \n",
      "Insurer to the Insured where, the payments of the costs \n",
      "of treatment undergone by the Insured in accordance \n",
      "with the Policy terms and conditions are directly made \n",
      "to the network provider by the Insurer to the extent pre-\n"
     ]
    }
   ],
   "source": [
    "print(chunked_policies['Elevate Policy Wordings.pdf'][0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Comparison.pdf', 'Elevate Policy Wordings.pdf', 'Health AdvantEdge_Policy wordings_IL.pdf', 'policy-wordings_maxprotect.pdf'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_policies.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison.pdf:- 3\n",
      "Elevate Policy Wordings.pdf:- 134\n",
      "Health AdvantEdge_Policy wordings_IL.pdf:- 117\n",
      "policy-wordings_maxprotect.pdf:- 73\n"
     ]
    }
   ],
   "source": [
    "for i in chunked_policies.keys():\n",
    "    print(f\"{i}:- {len(chunked_policies[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens to be used:- 187801\n"
     ]
    }
   ],
   "source": [
    "### Making an instance just to count numbers of tokens and use summarize to make summary of all policies\n",
    "### Temperature 0 is for the reason that we do not want it to be creative\n",
    "llm = ChatOpenAI(temperature=0,model=\"gpt-3.5-turbo\")\n",
    "total=0\n",
    "for i in chunked_policies.keys():\n",
    "    for k in range(0,len(chunked_policies[i])):\n",
    "        total+=llm.get_num_tokens(chunked_policies[i][k].page_content)\n",
    "print(f\"Total Tokens to be used:- {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FAILED LOGIC (Tried to summarize the 3 docs to reduce the token size)\n",
    "### the chain type have 3 type \n",
    "### map_reduce (each chuck is summarised and Combines all partial summaries into one final summary), \n",
    "### refine (keeps on refining when new chunck is added, much detailed), \n",
    "### stuff (load all chucks at onces and used as single prompt to summarize)\n",
    "\n",
    "# summary_chain = load_summarize_chain(llm, chain_type=\"refine\")\n",
    "# final_results = {}\n",
    "# for policy_name, docs in chunked_policies.items():\n",
    "#     print(f\"Summarizing policy: {policy_name}\")\n",
    "#     try:\n",
    "#         map_reduce_outputs = summary_chain({\"input_documents\": docs})\n",
    "#         final_summary = map_reduce_outputs[\"output_text\"]\n",
    "        \n",
    "#         summary_dir = \"policy_summaries\"\n",
    "#         os.makedirs(summary_dir, exist_ok=True)\n",
    "#         clean_filename = policy_name.replace('.pdf', '').replace(' ', '_')\n",
    "#         output_path = os.path.join(summary_dir, f\"{clean_filename}_summary.txt\")\n",
    "#         with open(output_path, 'w', encoding='utf-8') as f:\n",
    "#             f.write(final_summary)\n",
    "        \n",
    "#         print(f\"Summary for {policy_name} saved to {output_path}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing {policy_name}: {e}\")\n",
    "        \n",
    "# print(\"All policy summaries completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Other Logic to use Vector DB to make a local DB storage and use emmbeding of all the chuncks\n",
    "### creating embedding for all documents that has to be stored in vector db\n",
    "### Embeddings are made because ChromaDB stores and retrieves data based on semantic similarity, and embeddings are the numerical representations that capture this semantic meaning.\n",
    "embeddings = OpenAIEmbeddings()\n",
    "all_docs_list = []\n",
    "for policy_name, docs in chunked_policies.items():\n",
    "    for doc in docs:\n",
    "        doc.metadata['source_policy'] = policy_name\n",
    "        all_docs_list.append(doc)\n",
    "#Creating local vector db\n",
    "persist_directory = 'db_chroma'\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_docs_list,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:-  Hi\n",
      "Assistant:-  Hello! How can I assist you today?\n",
      "User:-  mujko apni wife k liye insurance lena h\n",
      "Assistant:-  Kya aapko specific requirements hain jaise coverage amount ya specific benefits?\n",
      "User:-  my wife recently had her gal bladder removed, we are looking around 10 lacks coverage and her age is 32\n",
      "Assistant:-  Given your wife's recent gallbladder surgery and age of 32, you may benefit from the Health AdvantEdge_Policy wordings_IL. This policy can provide coverage up to 10 lakhs for various medical needs, including post-surgery care. Would you like more information on this policy option?\n",
      "User:-  give me more information that can benifit my wife condition with AdvantEdge_Policy wordings_IL\n",
      "Assistant:-  The Health AdvantEdge_Policy wordings_IL can provide comprehensive coverage for your wife's medical needs, including post-surgery care for her recent gall bladder removal. This policy offers coverage for various medical expenses incurred during hospitalization and can help alleviate the financial burden associated with medical treatment. Additionally, the policy may include benefits such as pre and post-hospitalization expenses, day care procedures, and ambulance charges, which can benefit your wife's overall health and well-being. If you would like more detailed information on how this policy can specifically benefit your wife's condition, please let me know any specific concerns or requirements you may have.\n",
      "User:-  okay, can you assist me the purchasing details\n",
      "Assistant:-  For purchasing details, I recommend contacting Shaurya Vashisth. They can provide you with further guidance on the procedure and pricing for the policy you are interested in.\n",
      "User:-  thank you\n",
      "Assistant:-  You're welcome! If you have any more questions or need further assistance, feel free to ask.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=1,model=\"gpt-3.5-turbo\")\n",
    "### Setting up Prompt\n",
    "prompt_template = \"\"\"You are a professional insurance advisor specializing in Elevate Policy Wordings, Health AdvantEdge_Policy wordings_IL, and Maxprotect. \n",
    "You must use the provided context to answer the user's questions accurately and comprehensively.\n",
    "If the user's query lacks sufficient information, ask clarifying questions to obtain these details. \n",
    "Be proactive in gathering information to provide personalized advice.\n",
    "Explain policy features in the context of the user's needs. For example, if discussing maternity coverage, explain how it would benefit a user planning to start a family.\n",
    "\n",
    "If the user asks about pricing, refer them to Shaurya Vashisth.\n",
    "\n",
    "The communication can be in english, hindi or hinglish.\n",
    "Give answers in small sentenses.\n",
    "\n",
    "User History: {user_history}\n",
    "Assistant History: {assistant_history}\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"user_history\",\"assistant_history\",\"context\", \"question\"]\n",
    ")\n",
    "### Setting up RetrievalQA to retive similar chuncks\n",
    "### K = number of top k relevent chuncks\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")\n",
    "\n",
    "chat_logs = {\"User\":\"\",\"Assistant\":\"\"}\n",
    "\n",
    "while True:\n",
    "    Query = input(\"User:- \")\n",
    "    if Query.lower() == \"quit\":\n",
    "        break\n",
    "    else:\n",
    "        docs = retriever.invoke(Query)\n",
    "        full_prompt = PROMPT.format(user_history=chat_logs['User'],\n",
    "                assistant_history=chat_logs['Assistant'],\n",
    "                context=\"\\n\\n\".join(doc.page_content for doc in docs),\n",
    "                question=Query)\n",
    "        response = llm.invoke(full_prompt)\n",
    "        print(\"User:- \",Query)\n",
    "        print(\"Assistant:- \",response.content)\n",
    "        chat_logs['User'] = Query\n",
    "        chat_logs['Assistant'] = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
