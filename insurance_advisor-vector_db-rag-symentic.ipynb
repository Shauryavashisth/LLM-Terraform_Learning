{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\shaur\\\\Desktop\\\\icici policies wording'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, nltk, re\n",
    "from langchain.document_loaders import PyPDFLoader, WebBaseLoader\n",
    "from langchain.text_splitter import NLTKTextSplitter,RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from pathlib import Path as p\n",
    "os.environ[\"OPENAI_API_KEY\"]=open(r\"C:\\Users\\shaur\\Downloads\\chat_gpt_key.txt\",'r').read()\n",
    "os.chdir(r\"C:\\Users\\shaur\\Desktop\\icici policies wording\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pages from Comparison.pdf:- 3\n",
      "Length of pages from Elevate Policy Wordings.pdf:- 45\n",
      "Length of pages from Health AdvantEdge_Policy wordings_IL.pdf:- 51\n",
      "Length of pages from policy-wordings_maxprotect.pdf:- 40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['Comparison.pdf', 'Elevate Policy Wordings.pdf', 'Health AdvantEdge_Policy wordings_IL.pdf', 'policy-wordings_maxprotect.pdf'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_policies_pdfs = [i for i in os.listdir() if '.pdf' in i]\n",
    "all_policies_dict = {}\n",
    "for i in range(0,len(all_policies_pdfs)):\n",
    "    loader = PyPDFLoader(all_policies_pdfs[i])\n",
    "    pages = loader.load()\n",
    "    pages = [page.page_content for page in pages]\n",
    "    print(f\"Length of pages from {all_policies_pdfs[i]}:- {len(pages)}\")\n",
    "    all_policies_dict[all_policies_pdfs[i]] = pages\n",
    "all_policies_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### (FAILED) getting summary from Policybazar for the comparision of these 3 policy\n",
    "# loader = WebBaseLoader(\"https://pbhealth.policybazaar.com/quote-compare-2?encenq=emRrNkN3aEk4TlBwdzZwLzc4NXRZMGRlRzFkbE5pL2JYQmlOaFBLUm5iUT0&enquiryid=NzU3NzI1ODk0&k=eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJFbnF1aXJ5SWQiOjc1NzcyNTg5NCwiRXhwaXJ5VGltZSI6MTc0NTc0MjM2OSwiUm9sZSI6bnVsbH0.GkSkfmCCjxhe3pYejDkhMyVvKZj2LxVR3JDBOujUE1RzG3W-oWkxJ32Nyb9e33WEvEVqflbUduzokJ5Nju8XepIY0kjivduTKeyfZhljIMkWjCZ9IxJnYw9_dQg23z0BAldA36UL9Tw-e6VgM46Do7ehY7byPWdYfRcE1zCkQyc&plan=80950-1000000-Elevate-3-ICICI%20Lombard-8739-0-2-1&plan=80843-10000000-Max%20Protect%20Classic-3-ICICI%20Lombard-16724-0-2-1&plan=80045-1000000-Health%20AdvantEdge-3-ICICI%20Lombard-12282-0-2-1&profileid=147272833&utm_source=MYACC_M\")\n",
    "# documents = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_policies_dict['Elevate Policy Wordings.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_policies_dict['Health AdvantEdge_Policy wordings_IL.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_policies_dict['policy-wordings_maxprotect.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Removing footer details from the PDF's\n",
    "\n",
    "repeted_text_0 = 'IRDA Reg. No. 115\\nMailing Address:\\n601 / 602, 6th Floor, Interface Building No. 16,\\nNew Link Road, Malad (West), \\nMumbai - 400 064.CIN:  L67200MH2000PLC129408\\nRegistered Office Address:\\nICICI Lombard House, 414, P Balu Marg, Off \\nVeer Savarkar Road, Nr Siddhi Vinayak Temple, \\nPrabhadevi, Mumbai - 400 025.UIN: ICIHLIP25048V042425 Product Name: Elevate\\nToll free No.  : 1800 2666  \\nAlternate No.: 86552 22666 (Chargeable)\\nWebsite :  www.iciclombard.com\\nE-mail : customersupport@icicilombard.comICICI Lombard General Insurance Company Limited'\n",
    "repeted_text_1 = 'Health AdvantEdge  \\nICICI Lombard General Insurance Company Limited  \\n       IRDA  Reg. No. 115                            CIN : L67200MH2000PLC129408                                  UIN: ICIHLIP24182V042324     Health A dvantEdge  \\n       Mailing A ddress:                              Registered Office A ddress:                                Toll free no : 1800 2666   \\n601 & 602, 6th Floor, Interf ace 16,    ICICI Lombard House, 414, P Balu Marg,                     A lternate no :  86552 2 2666 (chargeable)   \\nNew Linking Road, Malad (West)      Of f  Veer Sav arkar Road, Nr Siddhi Vinay ak Temple,    E-mail : customersupport@icicilombard.com  \\n    Mumbai - 400 064                             Prabhadev i, Mumbai 400 025                                        Website : www.icicilombard.com   '\n",
    "repeted_text_2 = 'Annexure I  MaxProtect  Policy w ordings  \\nIRDAI reg. no.: 115                CIN: L67200MH20000PLC129408   UIN: ICIHLIP24084V012324'\n",
    "for i in all_policies_dict.keys():\n",
    "    for k in [repeted_text_0,repeted_text_1,repeted_text_2]:\n",
    "        all_policies_dict[i] = [page.replace(k.strip(), '').strip() for page in all_policies_dict[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Symentic based chunking\n",
    "### Using RecursiveCharacterTextSplitter (found that the context was missing or changed and the sentenses were getting cut from between)\n",
    "### Using NLTKTextSplitter (found that the context was being saved and the sentenses were complete)\n",
    "# splitter = NLTKTextSplitter(chunk_size=1200, chunk_overlap=300)\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2500,\n",
    "    chunk_overlap=1000,\n",
    "    separators=[\"\\n\\n\", \"\\n\", r\"\\. \\s\"]\n",
    ")\n",
    "chunked_policies = {}\n",
    "for i, full_text in all_policies_dict.items():\n",
    "    full_text = \"\\n\".join(full_text)\n",
    "    docs = splitter.create_documents([full_text])\n",
    "    chunked_policies[i] = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a. PREAMBLE:\n",
      "  ICICI Lombard General Insurance Company Limited \n",
      "(“We/Us”), having received a Proposal and the premium \n",
      "from the Proposer named in Part A of the Policy \n",
      "(hereinafter referred to as the “Policy Schedule”) and the \n",
      "said Proposal form with any statement, report or other \n",
      "document leading to the issue of this Policy and referred \n",
      "to therein having been accepted and agreed to by Us \n",
      "and the Proposer as the basis of this contract do, by this \n",
      "Policy agree, in consideration of and subject to the due \n",
      "receipt of the subsequent premiums, as set out in the \n",
      "Policy Schedule. \n",
      "  Further, subject to the Policy terms and conditions that \n",
      "on proof to Our satisfaction of the compensation having \n",
      "become payable as set out in the Policy Schedule to the \n",
      "said person or persons claiming payment or occurencean \n",
      "event upon which one or more benefits become payable \n",
      "under this Policy, the Annual Sum Insured / appropriate \n",
      "benefit amount will be paid by Us.\n",
      "b. DEFINITIONS:\n",
      "  For the purposes of this Policy, the terms specified below \n",
      "shall have the meaning set forth wherever appearing/\n",
      "specified in this Policy or related Add-ons/Optional \n",
      "Covers:\n",
      "  Where the context so requires, references to the singular \n",
      "shall also include references to the plural and references \n",
      "to any gender shall include references to all genders. \n",
      "Further any references to statutory enactment include \n",
      "subsequent changes to the same.\n",
      "i.\t Standard\tDefinitions\t\n",
      "  “Accident”  means a sudden, unforeseen and involuntary \n",
      "event caused by external, visible and violent means. \n",
      " \t“Any\tone\tIllness”  means continuous period of Illness \n",
      "and it includes a relapse within 45 days from the date of \n",
      "last consultation with the Hospital/Nursing Home where \n",
      "treatment may have been taken. \n",
      "  “Ayush\tTreatment”  refers to the medical and / or \n",
      "hospitalization treatments given under ‘Ayurveda, Yoga \n",
      "and Naturopathy, Unani, Siddha and Homeopathy \n",
      "systems. \n",
      " \t“Break\tin\tpolicy”  means the period of gap that occurs at \n",
      "the end of the existing policy term / installment premium \n",
      "due date, when the premium due for renewal on a given \n",
      "policy or installment premium due is not paid on or before \n",
      "the premium renewal date or grace period. \n",
      "  “Cashless\t facility”  means a facility extended by the \n",
      "Insurer to the Insured where, the payments of the costs \n",
      "of treatment undergone by the Insured in accordance \n",
      "with the Policy terms and conditions are directly made \n",
      "to the network provider by the Insurer to the extent pre-\n"
     ]
    }
   ],
   "source": [
    "print(chunked_policies['Elevate Policy Wordings.pdf'][0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Comparison.pdf', 'Elevate Policy Wordings.pdf', 'Health AdvantEdge_Policy wordings_IL.pdf', 'policy-wordings_maxprotect.pdf'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_policies.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison.pdf:- 3\n",
      "Elevate Policy Wordings.pdf:- 134\n",
      "Health AdvantEdge_Policy wordings_IL.pdf:- 117\n",
      "policy-wordings_maxprotect.pdf:- 73\n"
     ]
    }
   ],
   "source": [
    "for i in chunked_policies.keys():\n",
    "    print(f\"{i}:- {len(chunked_policies[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens to be used:- 187801\n"
     ]
    }
   ],
   "source": [
    "### Making an instance just to count numbers of tokens and use summarize to make summary of all policies\n",
    "### Temperature 0 is for the reason that we do not want it to be creative\n",
    "llm = ChatOpenAI(temperature=0,model=\"gpt-3.5-turbo\")\n",
    "total=0\n",
    "for i in chunked_policies.keys():\n",
    "    for k in range(0,len(chunked_policies[i])):\n",
    "        total+=llm.get_num_tokens(chunked_policies[i][k].page_content)\n",
    "print(f\"Total Tokens to be used:- {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FAILED LOGIC (Tried to summarize the 3 docs to reduce the token size)\n",
    "### the chain type have 3 type \n",
    "### map_reduce (each chuck is summarised and Combines all partial summaries into one final summary), \n",
    "### refine (keeps on refining when new chunck is added, much detailed), \n",
    "### stuff (load all chucks at onces and used as single prompt to summarize)\n",
    "\n",
    "# summary_chain = load_summarize_chain(llm, chain_type=\"refine\")\n",
    "# final_results = {}\n",
    "# for policy_name, docs in chunked_policies.items():\n",
    "#     print(f\"Summarizing policy: {policy_name}\")\n",
    "#     try:\n",
    "#         map_reduce_outputs = summary_chain({\"input_documents\": docs})\n",
    "#         final_summary = map_reduce_outputs[\"output_text\"]\n",
    "        \n",
    "#         summary_dir = \"policy_summaries\"\n",
    "#         os.makedirs(summary_dir, exist_ok=True)\n",
    "#         clean_filename = policy_name.replace('.pdf', '').replace(' ', '_')\n",
    "#         output_path = os.path.join(summary_dir, f\"{clean_filename}_summary.txt\")\n",
    "#         with open(output_path, 'w', encoding='utf-8') as f:\n",
    "#             f.write(final_summary)\n",
    "        \n",
    "#         print(f\"Summary for {policy_name} saved to {output_path}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing {policy_name}: {e}\")\n",
    "        \n",
    "# print(\"All policy summaries completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Other Logic to use Vector DB to make a local DB storage and use emmbeding of all the chuncks\n",
    "### creating embedding for all documents that has to be stored in vector db\n",
    "### Embeddings are made because ChromaDB stores and retrieves data based on semantic similarity, and embeddings are the numerical representations that capture this semantic meaning.\n",
    "embeddings = OpenAIEmbeddings()\n",
    "all_docs_list = []\n",
    "for policy_name, docs in chunked_policies.items():\n",
    "    for doc in docs:\n",
    "        doc.metadata['source_policy'] = policy_name\n",
    "        all_docs_list.append(doc)\n",
    "#Creating local vector db\n",
    "persist_directory = 'db_chroma'\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_docs_list,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:-  Hi\n",
      "Assistant:-  Hello! How can I assist you today?\n",
      "User:-  mujko apni wife k liye insurance lena h\n",
      "Assistant:-  Kya aap batayenge ki aapki wife ke liye specific requirements kya hain? Jaise ki cover amount, policy term, ya koi specific coverage?\n",
      "User:-  my wife wants an cover upto 10 lacks and she recently had her gal bladder removed\n",
      "Assistant:-  Based on your wife's recent medical history of gall bladder removal, I recommend looking into our Health AdvantEdge_Policy Wordings_IL for comprehensive coverage.\n",
      "The policy can provide coverage of up to Rs. 10 Lakhs for various medical expenses, including hospitalization, surgeries, and more.\n",
      "It's important to disclose your wife's recent gall bladder surgery to ensure proper coverage and avoid any disputes during claims.\n",
      "I can provide you with detailed information and assist in customizing a policy that suits your wife's needs. Let me know if you would like to proceed with this option.\n",
      "User:-  sure, assist me with Health AdvantEdge_Policy Wordings_IL plan\n",
      "Assistant:-  The Health AdvantEdge_Policy Wordings_IL plan offers coverage of up to Rs. 10 Lakhs for various medical expenses, including surgeries and hospitalization.\n",
      "It includes benefits like ambulance assistance for ground medical transportation to the nearest hospital, clinic, or nursing home.\n",
      "You can check the updated list of cities/locations where these services are provided on our website.\n",
      "It's essential to disclose any recent medical history, such as your wife's gall bladder removal, to ensure proper coverage.\n",
      "I can assist you in customizing a policy that best suits your wife's needs. Let me know if you would like to proceed with this option.\n",
      "User:-  can we add our 6 months old child in Health AdvantEdge_Policy Wordings_IL?\n",
      "Assistant:-  Yes, you can add your 6-month-old child to the Health AdvantEdge_Policy Wordings_IL policy as a newly born baby with relevant documentation.\n",
      "Make sure to provide the necessary documentation for the addition of your child to the policy.\n",
      "User:-  does Health AdvantEdge_Policy Wordings_IL have OPD health checkups?\n",
      "Assistant:-  Yes, the Health AdvantEdge_Policy Wordings_IL provides coverage for preventive health check-ups on a cashless basis up to ₹10,000 in a policy year for insured individuals who are at least 21 years old.\n",
      "User:-  Thank you, can you please assist me further?\n",
      "Assistant:-  Of course, I can assist you further. How can I help you today with your insurance policies?\n",
      "User:-  i need to proceed with purchase\n",
      "Assistant:-  Before proceeding with your purchase, could you please provide me with more details about your specific insurance needs or any questions you have regarding the Elevate Policy Wordings, Health AdvantEdge_Policy wordings_IL, or Maxprotect policies?\n",
      "User:-  i will move forward with Health AdvantEdge_Policy Wordings_IL\n",
      "Assistant:-  Before you proceed with the Health AdvantEdge_Policy Wordings_IL, could you please tell me more about your specific health insurance needs or any questions you have regarding this policy?\n",
      "User:-  no\n",
      "Assistant:-  Before you proceed with the Health AdvantEdge_Policy Wordings_IL, could you please tell me more about your specific health insurance needs or any questions you have regarding this policy?\n",
      "User:-  explain?\n",
      "Assistant:-  This policy provides a room with amenities like carafe, dining table, and meals for the patient's attendants. Additional food items are charged extra. It covers surgery or surgical procedures conducted by a medical practitioner for treatment or relief. Experimental treatments not based on established medical practice are excluded.\n",
      "User:-  what about the pricing?\n",
      "Assistant:-  For pricing details, I recommend reaching out to Shaurya Vashisth for accurate information related to Elevate Policy Wordings, Health AdvantEdge Policy wordings IL, and Maxprotect.\n",
      "User:-  Thank you\n",
      "Assistant:-  You're welcome! If you have any more questions or need further assistance, feel free to ask.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=1,model=\"gpt-3.5-turbo\")\n",
    "### Setting up Prompt\n",
    "prompt_template = \"\"\"You are a professional insurance advisor specializing in Elevate Policy Wordings, Health AdvantEdge_Policy wordings_IL, and Maxprotect. \n",
    "You must use the provided context and chat history to answer the user's questions accurately and comprehensively.\n",
    "If the user's query lacks sufficient information, ask clarifying questions to obtain these details. \n",
    "Be proactive in gathering information to provide personalized advice.\n",
    "Explain policy features in the context of the user's needs. For example, if discussing maternity coverage, explain how it would benefit a user planning to start a family.\n",
    "\n",
    "If the user asks about pricing, refer them to Shaurya Vashisth.\n",
    "\n",
    "The communication can be in english, hindi or hinglish.\n",
    "Give answers in small sentenses.\n",
    "\n",
    "User History: {user_history}\n",
    "Assistant History: {assistant_history}\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"user_history\",\"assistant_history\",\"context\", \"question\"]\n",
    ")\n",
    "### Setting up RetrievalQA to retive similar chuncks\n",
    "### K = number of top k relevent chuncks\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")\n",
    "\n",
    "chat_logs = {\"User\":\"\",\"Assistant\":\"\"}\n",
    "\n",
    "while True:\n",
    "    Query = input(\"User:- \")\n",
    "    if Query.lower() == \"quit\":\n",
    "        break\n",
    "    else:\n",
    "        docs = retriever.invoke(Query)\n",
    "        full_prompt = PROMPT.format(user_history=chat_logs['User'],\n",
    "                assistant_history=chat_logs['Assistant'],\n",
    "                context=\"\\n\\n\".join(doc.page_content for doc in docs),\n",
    "                question=Query)\n",
    "        response = llm.invoke(full_prompt)\n",
    "        print(\"User:- \",Query)\n",
    "        print(\"Assistant:- \",response.content)\n",
    "        chat_logs['User'] = Query\n",
    "        chat_logs['Assistant'] = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Tune on temprature, top-p and top-k\n",
    "# The final step is to generate the next token by sampling from this distribution \n",
    "# The temperature hyperparameter plays a critical role in this process. Mathematically speaking,\n",
    "\n",
    "# it is a very simple operation: model output logits are simply divided by the temperature:\n",
    "# temperature = 1: Dividing logits by one has no effect on the softmax outputs.\n",
    "# temperature < 1: Lower temperature makes the model more confident and deterministic by sharpening the probability distribution, leading to more predictable outputs.\n",
    "# temperature > 1: Higher temperature creates a softer probability distribution, allowing for more randomness in the generated text – what some refer to as model “creativity”.\n",
    "\n",
    "# In addition, the sampling process can be further refined using top-k and top-p parameters:\n",
    "# top-k sampling: Limits the candidate tokens to the top k tokens with the highest probabilities, filtering out less likely options.\n",
    "# top-p sampling: Considers the smallest set of tokens whose cumulative probability exceeds a threshold p, ensuring that only the most likely tokens contribute while still allowing for diversity.\n",
    "# By tuning temperature, top-k, and top-p, you can balance between deterministic and diverse outputs, tailoring the model's behavior to your specific needs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
