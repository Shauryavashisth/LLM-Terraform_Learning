{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaur\\AppData\\Roaming\\Python\\Python39\\site-packages\\langchain_community\\document_loaders\\blob_loaders\\file_system.py:5: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_community.document_loaders.blob_loaders.schema import Blob, BlobLoader\n",
      "C:\\Users\\shaur\\AppData\\Roaming\\Python\\Python39\\site-packages\\langchain_community\\document_loaders\\__init__.py:221: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_community.document_loaders.youtube import (\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\shaur\\\\Desktop\\\\icici policies wording'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, nltk, re\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import NLTKTextSplitter,RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from pathlib import Path as p\n",
    "os.environ[\"OPENAI_API_KEY\"]=open(r\"C:\\Users\\shaur\\Downloads\\chat_gpt_key.txt\",'r').read()\n",
    "os.chdir(r\"C:\\Users\\shaur\\Desktop\\icici policies wording\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pages from Elevate Policy Wordings.pdf:- 45\n",
      "Length of pages from Health AdvantEdge_Policy wordings_IL.pdf:- 51\n",
      "Length of pages from policy-wordings_maxprotect.pdf:- 40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['Elevate Policy Wordings.pdf', 'Health AdvantEdge_Policy wordings_IL.pdf', 'policy-wordings_maxprotect.pdf'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_policies_pdfs = [i for i in os.listdir() if '.pdf' in i]\n",
    "all_policies_dict = {}\n",
    "for i in range(0,len(all_policies_pdfs)):\n",
    "    loader = PyPDFLoader(all_policies_pdfs[i])\n",
    "    pages = loader.load()\n",
    "    pages = [page.page_content for page in pages]\n",
    "    print(f\"Length of pages from {all_policies_pdfs[i]}:- {len(pages)}\")\n",
    "    all_policies_dict[all_policies_pdfs[i]] = pages\n",
    "all_policies_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_policies_dict['Elevate Policy Wordings.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_policies_dict['Health AdvantEdge_Policy wordings_IL.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_policies_dict['policy-wordings_maxprotect.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeted_text_0 = 'IRDA Reg. No. 115\\nMailing Address:\\n601 / 602, 6th Floor, Interface Building No. 16,\\nNew Link Road, Malad (West), \\nMumbai - 400 064.CIN:  L67200MH2000PLC129408\\nRegistered Office Address:\\nICICI Lombard House, 414, P Balu Marg, Off \\nVeer Savarkar Road, Nr Siddhi Vinayak Temple, \\nPrabhadevi, Mumbai - 400 025.UIN: ICIHLIP25048V042425 Product Name: Elevate\\nToll free No.  : 1800 2666  \\nAlternate No.: 86552 22666 (Chargeable)\\nWebsite :  www.iciclombard.com\\nE-mail : customersupport@icicilombard.comICICI Lombard General Insurance Company Limited'\n",
    "repeted_text_1 = 'Health AdvantEdge  \\nICICI Lombard General Insurance Company Limited  \\n       IRDA  Reg. No. 115                            CIN : L67200MH2000PLC129408                                  UIN: ICIHLIP24182V042324     Health A dvantEdge  \\n       Mailing A ddress:                              Registered Office A ddress:                                Toll free no : 1800 2666   \\n601 & 602, 6th Floor, Interf ace 16,    ICICI Lombard House, 414, P Balu Marg,                     A lternate no :  86552 2 2666 (chargeable)   \\nNew Linking Road, Malad (West)      Of f  Veer Sav arkar Road, Nr Siddhi Vinay ak Temple,    E-mail : customersupport@icicilombard.com  \\n    Mumbai - 400 064                             Prabhadev i, Mumbai 400 025                                        Website : www.icicilombard.com   '\n",
    "repeted_text_2 = 'Annexure I  MaxProtect  Policy w ordings  \\nIRDAI reg. no.: 115                CIN: L67200MH20000PLC129408   UIN: ICIHLIP24084V012324'\n",
    "for i in all_policies_dict.keys():\n",
    "    for k in [repeted_text_0,repeted_text_1,repeted_text_2]:\n",
    "        all_policies_dict[i] = [page.replace(k.strip(), '').strip() for page in all_policies_dict[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1338, which is longer than the specified 1200\n",
      "Created a chunk of size 1338, which is longer than the specified 1200\n",
      "Created a chunk of size 1338, which is longer than the specified 1200\n"
     ]
    }
   ],
   "source": [
    "# splitter = RecursiveCharacterTextSplitter(\n",
    "#     chunk_size=1500,\n",
    "#     chunk_overlap=200,\n",
    "#     separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
    "# )\n",
    "splitter = NLTKTextSplitter(chunk_size=1200, chunk_overlap=200)\n",
    "chunked_policies = {}\n",
    "for i, full_text in all_policies_dict.items():\n",
    "    full_text = \"\\n\".join(pages)\n",
    "    docs = splitter.create_documents([full_text])\n",
    "    chunked_policies[i] = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A co-payment does not reduce the Sum Insured.\n",
      "\n",
      "Cumulative Bonus  means any increase or a ddition in the Sum Insured granted by the insurer \n",
      "without an associated increase in premium  \n",
      " \n",
      "Day Care Centre  means any institution established for day care treatment of illness and/or \n",
      "injuries or a medical setup with a hospital and which has been registere d with the local \n",
      "Annexure I  MaxProtect  Policy w ordings  \n",
      "IRDAI reg.\n",
      "\n",
      "no.\n",
      "\n",
      ": 115                CIN: L67200MH20000PLC129408   UIN: ICIHLIP24084V012324  authorities, wherever applicable, and is under supervision of a registered and qualified medical \n",
      "practitioner AND must comply with all minimum criterion as under – \n",
      "i. has qualified nursing staff under its employment;  \n",
      "ii.\n",
      "\n",
      "has qualified medical practitioner/s in charge  \n",
      "iii.\n",
      "\n",
      "has fully equipped operation theatre of its own where surgical procedures are carried \n",
      "out; \n",
      "iv.\n",
      "\n",
      "maintains daily records of patients and will make these accessible to the insurance \n",
      "company’s authorized personnel .\n",
      "\n",
      "Day Care Treatment  means medical treatment, and/or Surgical Procedure which is  \n",
      "i.\n"
     ]
    }
   ],
   "source": [
    "print(chunked_policies['policy-wordings_maxprotect.pdf'][6].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Elevate Policy Wordings.pdf', 'Health AdvantEdge_Policy wordings_IL.pdf', 'policy-wordings_maxprotect.pdf'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_policies.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elevate Policy Wordings.pdf:- 120\n",
      "Health AdvantEdge_Policy wordings_IL.pdf:- 120\n",
      "policy-wordings_maxprotect.pdf:- 120\n"
     ]
    }
   ],
   "source": [
    "for i in chunked_policies.keys():\n",
    "    print(f\"{i}:- {len(chunked_policies[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens to be used:- 87690\n"
     ]
    }
   ],
   "source": [
    "# Making an instance just to count numbers of tokens and use summarize to make summary of all policies\n",
    "# Temperature 0 is for the reason that we do not want it to be creative\n",
    "llm = ChatOpenAI(temperature=0,model=\"gpt-3.5-turbo\")\n",
    "total=0\n",
    "for i in chunked_policies.keys():\n",
    "    for k in range(0,len(chunked_policies[i])):\n",
    "        total+=llm.get_num_tokens(chunked_policies[i][k].page_content)\n",
    "print(f\"Total Tokens to be used:- {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the chain type have 3 type \n",
    "# map_reduce (each chuck is summarised and Combines all partial summaries into one final summary), \n",
    "# refine (keeps on refining when new chunck is added, much detailed), \n",
    "# stuff (load all chucks at onces and used as single prompt to summarize)\n",
    "\n",
    "# summary_chain = load_summarize_chain(llm, chain_type=\"refine\")\n",
    "# final_results = {}\n",
    "# for policy_name, docs in chunked_policies.items():\n",
    "#     print(f\"Summarizing policy: {policy_name}\")\n",
    "#     try:\n",
    "#         map_reduce_outputs = summary_chain({\"input_documents\": docs})\n",
    "#         final_summary = map_reduce_outputs[\"output_text\"]\n",
    "        \n",
    "#         summary_dir = \"policy_summaries\"\n",
    "#         os.makedirs(summary_dir, exist_ok=True)\n",
    "#         clean_filename = policy_name.replace('.pdf', '').replace(' ', '_')\n",
    "#         output_path = os.path.join(summary_dir, f\"{clean_filename}_summary.txt\")\n",
    "#         with open(output_path, 'w', encoding='utf-8') as f:\n",
    "#             f.write(final_summary)\n",
    "        \n",
    "#         print(f\"Summary for {policy_name} saved to {output_path}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing {policy_name}: {e}\")\n",
    "        \n",
    "# print(\"All policy summaries completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating embedding for all documents\n",
    "embeddings = OpenAIEmbeddings()\n",
    "all_docs_list = []\n",
    "for policy_name, docs in chunked_policies.items():\n",
    "    for doc in docs:\n",
    "        doc.metadata['source_policy'] = policy_name\n",
    "        all_docs_list.append(doc)\n",
    "#Creating local vector db\n",
    "persist_directory = 'db_chroma'\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_docs_list,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:-  Hi\n",
      "Assistant:-  Hello! How can I assist you today?\n",
      "User:-  I am looking out for an Insurance plan\n",
      "Assistant:-  Based on the context provided, I recommend looking into the Elevate Policy Wordings, Health AdvantEdge_Policy wordings_IL, and Maxprotect insurance plans for your needs.\n",
      "User:-  sure help me get the best plan for myself\n",
      "Assistant:-  Based on the context provided, I recommend looking into the Elevate Policy Wordings, Health AdvantEdge_Policy wordings_IL, and Maxprotect insurance plans for your needs.\n",
      "User:-  okay, suggust which one exactly?\n",
      "Assistant:-  Based on the context provided, I recommend the MaxProtect insurance plan for your needs.\n",
      "User:-  why? MaxProtect?\n",
      "Assistant:-  Based on the context provided, the MaxProtect insurance plan offers assistance services for medical transportation and health facilitation, but the insured person is responsible for bearing the charges associated with actual services.\n"
     ]
    }
   ],
   "source": [
    "# K = number of top k relevent chuncks\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "prompt_template = \"\"\"You are a professional assistant who has to support the users to get the best Insurance plan.\n",
    "The Name of 3 policy are Elevate Policy Wordings, Health AdvantEdge_Policy wordings_IL and Maxprotect.\n",
    "You have to use the following pieces of context derived from 3 insurance policy documents to answer the question at the end. the User does not know anything about the policy.\n",
    "If you don't know the answer based on the provided context, just say that you don't know, don't try to make up an answer.\n",
    "Provide a concise answer based *only* on the context.\n",
    "\n",
    "While suggusting insurance plan these details from the user can assist you to guide them better, ask if required. the details are as follow.\n",
    "1. is the policy has to be bought for Self, Wife, Son, Daughter, Father, Mother or someone else?\n",
    "2. Gender and Age\n",
    "3. Health information like (medical history, including any pre-existing conditions, medications you are taking, and any surgeries or treatments)\n",
    "4. Lifestyle information like (life style habits, such as smoking or drinking, as well as any risky hobbies or activities you participate)\n",
    "5. Occupation information like (information about occupation, including your job title, income, and any workplace hazards you may face)\n",
    "\n",
    "User history of the conversation is: {user_history}\n",
    "Assistant history of the conversation is: {assistant_history}\n",
    "If no conversation is found in History this conversation is fresh and greet the User.\n",
    "If conversation is found the no need to greet agian.\n",
    "\n",
    "New Context:{context}\n",
    "New Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"user_history\",\"assistant_history\",\"context\", \"question\"]\n",
    ")\n",
    "# Setting up RetrievalQA to retive similar chuncks\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")\n",
    "\n",
    "chat_logs = {\"User\":\"\",\"Assistant\":\"\"}\n",
    "\n",
    "while True:\n",
    "    Query = input(\"User:- \")\n",
    "    if Query.lower() == \"quit\":\n",
    "        break\n",
    "    else:\n",
    "        docs = retriever.get_relevant_documents(Query)\n",
    "        full_prompt = PROMPT.format(user_history=chat_logs['User'],\n",
    "                assistant_history=chat_logs['Assistant'],\n",
    "                context=\"\\n\\n\".join(doc.page_content for doc in docs),\n",
    "                question=Query)\n",
    "        response = llm.invoke(full_prompt)\n",
    "        print(\"User:- \",Query)\n",
    "        print(\"Assistant:- \",response.content)\n",
    "        chat_logs['User'] = Query\n",
    "        chat_logs['Assistant'] = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
