{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaur\\AppData\\Roaming\\Python\\Python39\\site-packages\\langchain_community\\document_loaders\\blob_loaders\\file_system.py:5: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_community.document_loaders.blob_loaders.schema import Blob, BlobLoader\n",
      "C:\\Users\\shaur\\AppData\\Roaming\\Python\\Python39\\site-packages\\langchain_community\\document_loaders\\__init__.py:221: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_community.document_loaders.youtube import (\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\shaur\\\\Desktop\\\\icici policies wording'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, nltk, re\n",
    "from langchain.document_loaders import PyPDFLoader, WebBaseLoader\n",
    "from langchain.text_splitter import NLTKTextSplitter,RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from pathlib import Path as p\n",
    "os.environ[\"OPENAI_API_KEY\"]=open(r\"C:\\Users\\shaur\\Downloads\\chat_gpt_key.txt\",'r').read()\n",
    "os.chdir(r\"C:\\Users\\shaur\\Desktop\\icici policies wording\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pages from Elevate Policy Wordings.pdf:- 45\n",
      "Length of pages from Health AdvantEdge_Policy wordings_IL.pdf:- 51\n",
      "Length of pages from policy-wordings_maxprotect.pdf:- 40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['Elevate Policy Wordings.pdf', 'Health AdvantEdge_Policy wordings_IL.pdf', 'policy-wordings_maxprotect.pdf'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_policies_pdfs = [i for i in os.listdir() if '.pdf' in i]\n",
    "all_policies_dict = {}\n",
    "for i in range(0,len(all_policies_pdfs)):\n",
    "    loader = PyPDFLoader(all_policies_pdfs[i])\n",
    "    pages = loader.load()\n",
    "    pages = [page.page_content for page in pages]\n",
    "    print(f\"Length of pages from {all_policies_pdfs[i]}:- {len(pages)}\")\n",
    "    all_policies_dict[all_policies_pdfs[i]] = pages\n",
    "all_policies_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### (FAILED) getting summary from Policybazar for the comparision of these 3 policy\n",
    "# loader = WebBaseLoader(\"https://pbhealth.policybazaar.com/quote-compare-2?encenq=emRrNkN3aEk4TlBwdzZwLzc4NXRZMGRlRzFkbE5pL2JYQmlOaFBLUm5iUT0&enquiryid=NzU3NzI1ODk0&k=eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJFbnF1aXJ5SWQiOjc1NzcyNTg5NCwiRXhwaXJ5VGltZSI6MTc0NTc0MjM2OSwiUm9sZSI6bnVsbH0.GkSkfmCCjxhe3pYejDkhMyVvKZj2LxVR3JDBOujUE1RzG3W-oWkxJ32Nyb9e33WEvEVqflbUduzokJ5Nju8XepIY0kjivduTKeyfZhljIMkWjCZ9IxJnYw9_dQg23z0BAldA36UL9Tw-e6VgM46Do7ehY7byPWdYfRcE1zCkQyc&plan=80950-1000000-Elevate-3-ICICI%20Lombard-8739-0-2-1&plan=80843-10000000-Max%20Protect%20Classic-3-ICICI%20Lombard-16724-0-2-1&plan=80045-1000000-Health%20AdvantEdge-3-ICICI%20Lombard-12282-0-2-1&profileid=147272833&utm_source=MYACC_M\")\n",
    "# documents = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_policies_dict['Elevate Policy Wordings.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_policies_dict['Health AdvantEdge_Policy wordings_IL.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_policies_dict['policy-wordings_maxprotect.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Removing footer details from the PDF's\n",
    "\n",
    "repeted_text_0 = 'IRDA Reg. No. 115\\nMailing Address:\\n601 / 602, 6th Floor, Interface Building No. 16,\\nNew Link Road, Malad (West), \\nMumbai - 400 064.CIN:  L67200MH2000PLC129408\\nRegistered Office Address:\\nICICI Lombard House, 414, P Balu Marg, Off \\nVeer Savarkar Road, Nr Siddhi Vinayak Temple, \\nPrabhadevi, Mumbai - 400 025.UIN: ICIHLIP25048V042425 Product Name: Elevate\\nToll free No.  : 1800 2666  \\nAlternate No.: 86552 22666 (Chargeable)\\nWebsite :  www.iciclombard.com\\nE-mail : customersupport@icicilombard.comICICI Lombard General Insurance Company Limited'\n",
    "repeted_text_1 = 'Health AdvantEdge  \\nICICI Lombard General Insurance Company Limited  \\n       IRDA  Reg. No. 115                            CIN : L67200MH2000PLC129408                                  UIN: ICIHLIP24182V042324     Health A dvantEdge  \\n       Mailing A ddress:                              Registered Office A ddress:                                Toll free no : 1800 2666   \\n601 & 602, 6th Floor, Interf ace 16,    ICICI Lombard House, 414, P Balu Marg,                     A lternate no :  86552 2 2666 (chargeable)   \\nNew Linking Road, Malad (West)      Of f  Veer Sav arkar Road, Nr Siddhi Vinay ak Temple,    E-mail : customersupport@icicilombard.com  \\n    Mumbai - 400 064                             Prabhadev i, Mumbai 400 025                                        Website : www.icicilombard.com   '\n",
    "repeted_text_2 = 'Annexure I  MaxProtect  Policy w ordings  \\nIRDAI reg. no.: 115                CIN: L67200MH20000PLC129408   UIN: ICIHLIP24084V012324'\n",
    "for i in all_policies_dict.keys():\n",
    "    for k in [repeted_text_0,repeted_text_1,repeted_text_2]:\n",
    "        all_policies_dict[i] = [page.replace(k.strip(), '').strip() for page in all_policies_dict[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1338, which is longer than the specified 1200\n",
      "Created a chunk of size 1338, which is longer than the specified 1200\n",
      "Created a chunk of size 1338, which is longer than the specified 1200\n"
     ]
    }
   ],
   "source": [
    "### Symentic based chunking\n",
    "### Using RecursiveCharacterTextSplitter (found that the context was missing or changed and the sentenses were getting cut from between)\n",
    "# splitter = RecursiveCharacterTextSplitter(\n",
    "#     chunk_size=1500,\n",
    "#     chunk_overlap=200,\n",
    "#     separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
    "# )\n",
    "\n",
    "### Using NLTKTextSplitter (found that the context was being saved and the sentenses were complete)\n",
    "splitter = NLTKTextSplitter(chunk_size=1200, chunk_overlap=300)\n",
    "chunked_policies = {}\n",
    "for i, full_text in all_policies_dict.items():\n",
    "    full_text = \"\\n\".join(pages)\n",
    "    docs = splitter.create_documents([full_text])\n",
    "    chunked_policies[i] = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) Acute condition - Acute condition is a disease, illness or injury that is likely to respond \n",
      "quickly to treatment which aims to return the pers on to his or her state of health immediately \n",
      "before suffering the disease/illness/injury which leads to full recovery.\n",
      "\n",
      "b) Chronic condition  - A chronic condition is defined as a disease, illness, or injury that has \n",
      "one or more of the following characteristic s: \n",
      "1. it needs ongoing or long -term monitoring through consultations, examinations, \n",
      "check -ups, and / or tests  \n",
      "2. it needs ongoing or long -term control or relief of symptoms  \n",
      "3. it requires rehabilitation for the patient or for the patient  to be specially trained to  \n",
      "cope with it  \n",
      "4. it continues indefinitely  \n",
      "5.\n",
      "\n",
      "It recurs or is likely to recur  \n",
      " \n",
      "Injury  means any accidental physical bodily harm excluding illness or disease solely and \n",
      "directly caused by external, violent, visible and evident means which is verified and certifi ed \n",
      "by a Medical Practitioner.\n",
      "\n",
      "Immediate Family  means spouse, dependent children, brother(s), sister(s) and dependent \n",
      "parent(s) of the Insured.\n"
     ]
    }
   ],
   "source": [
    "print(chunked_policies['policy-wordings_maxprotect.pdf'][12].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Elevate Policy Wordings.pdf', 'Health AdvantEdge_Policy wordings_IL.pdf', 'policy-wordings_maxprotect.pdf'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_policies.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elevate Policy Wordings.pdf:- 130\n",
      "Health AdvantEdge_Policy wordings_IL.pdf:- 130\n",
      "policy-wordings_maxprotect.pdf:- 130\n"
     ]
    }
   ],
   "source": [
    "for i in chunked_policies.keys():\n",
    "    print(f\"{i}:- {len(chunked_policies[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens to be used:- 94047\n"
     ]
    }
   ],
   "source": [
    "### Making an instance just to count numbers of tokens and use summarize to make summary of all policies\n",
    "### Temperature 0 is for the reason that we do not want it to be creative\n",
    "llm = ChatOpenAI(temperature=0,model=\"gpt-3.5-turbo\")\n",
    "total=0\n",
    "for i in chunked_policies.keys():\n",
    "    for k in range(0,len(chunked_policies[i])):\n",
    "        total+=llm.get_num_tokens(chunked_policies[i][k].page_content)\n",
    "print(f\"Total Tokens to be used:- {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FAILED LOGIC (Tried to summarize the 3 docs to reduce the token size)\n",
    "### the chain type have 3 type \n",
    "### map_reduce (each chuck is summarised and Combines all partial summaries into one final summary), \n",
    "### refine (keeps on refining when new chunck is added, much detailed), \n",
    "### stuff (load all chucks at onces and used as single prompt to summarize)\n",
    "\n",
    "# summary_chain = load_summarize_chain(llm, chain_type=\"refine\")\n",
    "# final_results = {}\n",
    "# for policy_name, docs in chunked_policies.items():\n",
    "#     print(f\"Summarizing policy: {policy_name}\")\n",
    "#     try:\n",
    "#         map_reduce_outputs = summary_chain({\"input_documents\": docs})\n",
    "#         final_summary = map_reduce_outputs[\"output_text\"]\n",
    "        \n",
    "#         summary_dir = \"policy_summaries\"\n",
    "#         os.makedirs(summary_dir, exist_ok=True)\n",
    "#         clean_filename = policy_name.replace('.pdf', '').replace(' ', '_')\n",
    "#         output_path = os.path.join(summary_dir, f\"{clean_filename}_summary.txt\")\n",
    "#         with open(output_path, 'w', encoding='utf-8') as f:\n",
    "#             f.write(final_summary)\n",
    "        \n",
    "#         print(f\"Summary for {policy_name} saved to {output_path}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing {policy_name}: {e}\")\n",
    "        \n",
    "# print(\"All policy summaries completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Other Logic to use Vector DB to make a local DB storage and use emmbeding of all the chuncks\n",
    "### creating embedding for all documents that has to be stored in vector db\n",
    "### Embeddings are made because ChromaDB stores and retrieves data based on semantic similarity, and embeddings are the numerical representations that capture this semantic meaning.\n",
    "embeddings = OpenAIEmbeddings()\n",
    "all_docs_list = []\n",
    "for policy_name, docs in chunked_policies.items():\n",
    "    for doc in docs:\n",
    "        doc.metadata['source_policy'] = policy_name\n",
    "        all_docs_list.append(doc)\n",
    "#Creating local vector db\n",
    "persist_directory = 'db_chroma'\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_docs_list,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaur\\AppData\\Local\\Temp\\ipykernel_7300\\1688258039.py:46: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(Query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:-  Hu\n",
      "Assistant:-  I don't have enough information from the policy context provided to suggest the best insurance plan for you.\n",
      "User:-  Hi\n",
      "Assistant:-  Hi! How can I assist you today?\n",
      "User:-  I am looking for an insurance policy for my parents\n",
      "Assistant:-  Based on the context provided, the Elevate Policy Wordings and Health AdvantEdge_Policy wordings_IL do not specifically mention coverage for parents. However, the MaxProtect policy may be suitable for your parents as it mentions coverage for Insured Persons, which could include parents. It is recommended to review the specific details of the MaxProtect policy to determine if it meets your parents' insurance needs.\n",
      "User:-  could you tell me about it's features?\n",
      "Assistant:-  Based on the context provided, the MaxProtect policy offers features such as coverage for surgical procedures, provision of vegetarian meals for patient's relatives or attendants, and exclusion of unproven/experimental treatments. The policy also defines terms like Policy Period and Policy Year.\n",
      "User:-  both of my parents are above the age of 50, how much will i be charged?\n",
      "Assistant:-  Based on the context provided, the Elevate Policy Wordings does not specify the exact charges for individuals above the age of 50. It is recommended to contact the insurance provider directly for specific pricing details based on the age of your parents.\n"
     ]
    }
   ],
   "source": [
    "### Setting up Prompt\n",
    "prompt_template = \"\"\"You are a professional advisor who has to support the users to get the best Insurance plan.\n",
    "The Name of 3 policy are Elevate Policy Wordings, Health AdvantEdge_Policy wordings_IL and Maxprotect.\n",
    "You have to use the following pieces of context derived from 3 insurance policy documents to answer the question at the end. the User does not know anything about the policy.\n",
    "If you don't know the answer based on the provided context, just say that you don't know, don't try to make up an answer.\n",
    "Provide a concise answer based *only* on the context.\n",
    "\n",
    "While suggusting insurance plan these details from the user can assist you to guide them better, ask if required. the details are as follow.\n",
    "1. is the policy has to be bought for Self, Wife, Son, Daughter, Father, Mother or someone else?\n",
    "2. Gender and Age\n",
    "3. Health information like (medical history, including any pre-existing conditions, medications you are taking, and any surgeries or treatments)\n",
    "4. Lifestyle information like (life style habits, such as smoking or drinking, as well as any risky hobbies or activities you participate)\n",
    "5. Occupation information like (information about occupation, including your job title, income, and any workplace hazards you may face)\n",
    "\n",
    "User history of the conversation is: {user_history}\n",
    "Assistant history of the conversation is: {assistant_history}\n",
    "If no conversation is found in History this conversation is fresh and greet the User.\n",
    "If conversation is found the no need to greet agian.\n",
    "\n",
    "New Context:{context}\n",
    "New Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"user_history\",\"assistant_history\",\"context\", \"question\"]\n",
    ")\n",
    "### Setting up RetrievalQA to retive similar chuncks\n",
    "### K = number of top k relevent chuncks\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")\n",
    "\n",
    "chat_logs = {\"User\":\"\",\"Assistant\":\"\"}\n",
    "\n",
    "while True:\n",
    "    Query = input(\"User:- \")\n",
    "    if Query.lower() == \"quit\":\n",
    "        break\n",
    "    else:\n",
    "        docs = retriever.get_relevant_documents(Query)\n",
    "        full_prompt = PROMPT.format(user_history=chat_logs['User'],\n",
    "                assistant_history=chat_logs['Assistant'],\n",
    "                context=\"\\n\\n\".join(doc.page_content for doc in docs),\n",
    "                question=Query)\n",
    "        response = llm.invoke(full_prompt)\n",
    "        print(\"User:- \",Query)\n",
    "        print(\"Assistant:- \",response.content)\n",
    "        chat_logs['User'] = Query\n",
    "        chat_logs['Assistant'] = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
