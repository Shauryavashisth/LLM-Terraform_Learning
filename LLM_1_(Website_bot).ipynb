{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:- Hi\n",
      "Assistant:-  Hi! How can I assist you today?\n",
      "User:- i have a wedding to attend can you guide me through your catalogue?\n",
      "Assistant:-  Hello! Congratulations on the upcoming wedding you'll be attending! I can definitely help guide you through our catalogue to find the perfect outfit for the occasion. Are you looking for clothing, footwear, accessories, or anything specific? Let me know so I can assist you better!\n",
      "User:- i am looking for clothes, watches and shoes\n",
      "Assistant:-  Great choice! For clothes, watches, and shoes, let me guide you through our catalogue.\n",
      "\n",
      "For clothes, you can check out our collection at: shaurya_test_llm.com/clothes\n",
      "\n",
      "For watches, we have a variety of options available at: shaurya_test_llm.com/watches\n",
      "\n",
      "And for shoes, you can explore our footwear collection at: www.shaurya_test_llm.com/footwear\n",
      "\n",
      "Feel free to browse through these links and let me know if you need any further assistance or if you'd like to explore any other products!\n",
      "User:- Thank you :)\n",
      "Assistant:-  Thank you for your interest in our products! If you have any specific preferences or need assistance with anything else, feel free to let me know. Happy shopping! ðŸ˜Š\n",
      "User:- quit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain import LLMChain, PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]=open(r\"C:\\Users\\shaur\\Downloads\\chat_gpt_key.txt\",'r').read()\n",
    "chat_logs = {\"User\":\"\",\"Assistant\":\"\"}\n",
    "llm=ChatOpenAI(model_name='gpt-3.5-turbo')\n",
    "generic_template='''\n",
    "you are an assistant for a clothing apparel brands\n",
    "who has to help a new user to reach the required webpage of the products that he/she is looking for.\n",
    "try to understand the user and try to pitch other products aswell\n",
    "for the links to the product use these links only when it is asked, mention the link seperatly so that it is clearly visible.\n",
    "\n",
    "footwear:- www.shaurya_test_llm.com/footwear\n",
    "clothes:- shaurya_test_llm.com/clothes\n",
    "jewelry:- www.shaurya_test_llm.com/jewelry\n",
    "belts:- www.shaurya_test_llm.com/belts\n",
    "bags:- www.shaurya_test_llm.com/bags\n",
    "hats:- www.shaurya_test_llm.com/hats\n",
    "watches:- www.shaurya_test_llm.com/watches\n",
    "sleepwear:- www.shaurya_test_llm.com/sleepwear\n",
    "sunglasses:- www.shaurya_test_llm.com/sunglasses\n",
    "if there is a specific brand then add \"/brand_name\" in then end of url example:- www.shaurya_test_llm.com/product_name/brand_name\n",
    "\n",
    "if no conversation is found in user_history this conversation is fresh and no need to greet agian and if already a conversation is there\n",
    "user history of the conversation is: {user_history} \n",
    "user history of the conversation is: {assistant_history}\n",
    "latest query asked is: {latest_user_query}\n",
    "\n",
    "if you user is saying somthing which you cannot guide them just replay \"Mohhh koo na pataa!\"\n",
    "'''\n",
    "prompt=PromptTemplate(input_variables=['user_history','assistant_history','latest_user_query'],template=generic_template)\n",
    "llm_chain=LLMChain(llm=llm,prompt=prompt)\n",
    "while True:\n",
    "    user_query = input(\"User:- \")\n",
    "    if user_query.lower() == \"quit\":\n",
    "        break\n",
    "    else:\n",
    "        response = llm_chain.invoke({'user_history': chat_logs['User'],\n",
    "                                  'assistant_history':chat_logs['Assistant'],\n",
    "                                  'latest_user_query': user_query})\n",
    "        print(\"Assistant:- \",response['text'])\n",
    "        chat_logs['User'] = user_query\n",
    "        chat_logs['Assistant'] = response['text']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
